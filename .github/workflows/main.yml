name: CI/CD Pipeline Monster scrape - DockerHub

on:
  push:
    branches:
      - main

jobs:
  build_and_push: # Renamed job
    runs-on: ubuntu-latest
    environment: prod
    env:
      SCRAPE_URL : ${{ secrets.SCRAPE_URL }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.21'

      # 1. BUILD THE BINARY (Optional, Dockerfile can do this, but keeping it)
      - name: Build Go binary
        run: |
          go mod tidy
          CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o monster-scrape .

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # 2. LOG IN TO DOCKER HUB
      - name: Docker Login
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      # Define image tag based on your Docker ID
      - name: Set image tag
        id: meta
        run: echo "IMAGE_TAG=${{ secrets.DOCKER_USERNAME }}/monster-scrape:latest" >> $GITHUB_OUTPUT

      # 3. BUILD AND PUSH TO DOCKER HUB
      - name: Build and Push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.IMAGE_TAG }}

      # 4. DEPLOY TO VPS (Trigger a reload using docker compose)
      # This is the ONLY step needed on the VPS now.
      # It connects to the VPS and tells docker compose to check for updates.
      - name: Trigger Monster Trends Deployment Reload
        uses: appleboy/ssh-action@v0.1.7
        with:
          host: ${{ secrets.VPS_HOST }}
          username: deploy
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          script: |
            echo "${{ secrets.DOCKER_PASSWORD }}" | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin
            echo "New monster-scrape image pushed. Triggering docker compose pull/up..."
            
            # Navigate to the directory containing the docker-compose.yml file
            cd /home/deploy/
            
            docker stop monster-scrape || true
            docker rm monster-scrape || true
            docker stop monster-trends || true
            docker rm monster-trends || true 
            
            # Pull the latest images for all services
            docker compose pull
            
            # scrape_url environment variable
            echo "SCRAPE_URL=${{ secrets.SCRAPE_URL }}" > ./config.env 
            
            # Restart the stack to use the newly pulled image
            # The 'up' command will detect the new monster-scrape image and recreate
            # that container, then restart the trends container if it depends on it.
            echo "Current directory:"
            pwd
            echo "Contents:"
            ls -la
            docker compose up -d --force-recreate